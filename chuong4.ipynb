{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "mypan = pd.DataFrame([mydict], index= ['list', 'arr'])\n",
    "mypan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 2\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)\n",
    "see = ser.to_frame(name= 'arr')\n",
    "see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 3\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "ser3 = pd.concat({'ser1': ser1, 'ser2': ser2}, axis= 1)\n",
    "ser3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 4\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "dif1 = ser1[-ser1.isin(ser2)]\n",
    "dif1\n",
    "dif2 = ser2[-ser2.isin(ser1)]\n",
    "dif3 = pd.concat([dif1, dif2])\n",
    "dif3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 5\n",
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "print(ser.min())\n",
    "print(ser.quantile(0.25))\n",
    "print(ser.mean())\n",
    "print(ser.quantile(0.75))\n",
    "print(ser.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ce263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 6\n",
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size = 30)))\n",
    "#ta có 1 list là: ['a,b,c,d,e,f,g,h']\n",
    "#np.random.randint(8, size = 30) là tạo ra 1 dãy gồm 30 dòng và lựa chọn ngẫu nhiên trong list từ 0 đến 8\n",
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a84c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 7\n",
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "top = ser.value_counts().nlargest(2).index\n",
    "ser1 = ser.where(ser.isin(top), 'other')\n",
    "ser1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac9ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 8\n",
    "ser = pd.Series(np.random.random(20))\n",
    "deciles = pd.qcut(ser, 10, labels= [f'decile {i}' for i in range(1, 11)])\n",
    "deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84586af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 9\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "#tao ra 1 day co 35 dong voi moi dong co so ngau nhien tu 1 den 10\n",
    "ser = pd.DataFrame(ser.values.reshape(7, 5))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d7ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 10\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "ser[ser%3 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 11\n",
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "poc = [0, 4, 8, 14, 20]\n",
    "ser.iloc[poc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e531ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 12\n",
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "ser3 = pd.concat([ser1, ser2], axis= 1)\n",
    "ser3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab099dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 13\n",
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10 ,13])\n",
    "ser1[ser1.isin(ser2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 14\n",
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10) + np.random.random(10))\n",
    "median = (truth**2 + pred**2)/2\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 15\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "ser.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9862685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 16\n",
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "hieu = ser.shift(-1) - ser.shift(1)\n",
    "hieu[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 17\n",
    "from dateutil import parser\n",
    "ser = pd.Series(['01 Jan 2010', \n",
    "                 '02-02-2011',\n",
    "                 '20120303',\n",
    "                 '2013/04/04', \n",
    "                 '2014-05-05',\n",
    "                 '2015-06-06T12:20'])\n",
    "\n",
    "dates = ser.apply(lambda x: parser.parse(x))\n",
    "\n",
    "values = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "series = pd.Series(data= values, index= dates)\n",
    "\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 18\n",
    "emails = pd.Series(['buying a book at amazon.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "\n",
    "pattern = r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}'\n",
    "\n",
    "very_valid_emails = emails[emails.str.contains(pattern, regex= True)]\n",
    "\n",
    "print(very_valid_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 19\n",
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "\n",
    "no_confuse = pd.DataFrame({'Fruit': fruit, 'Weights': weights})\n",
    "\n",
    "each_fruit_average = no_confuse.groupby('Fruit')['Weights'].mean()\n",
    "\n",
    "each_fruit_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 20\n",
    "euro12 = pd.read_csv('Euro 2012 stats TEAM.csv')\n",
    "\n",
    "print(euro12.dtypes)\n",
    "print(euro12.shape)\n",
    "#1\n",
    "print(euro12['Goals'])\n",
    "#2\n",
    "the_number_of_team = euro12.shape['Team']\n",
    "print(the_number_of_team)\n",
    "#3\n",
    "print(euro12)\n",
    "#4\n",
    "discipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\n",
    "print(discipline)\n",
    "#5\n",
    "try_to_sort_smaller_number_with_two_colums = discipline.sort_values(by= ['Yellow Cards', 'Red Cards'], ascending= False)\n",
    "print(try_to_sort_smaller_number_with_two_colums)\n",
    "#6\n",
    "yellow_cards_average = discipline['Yellow Cards'].mean()\n",
    "print(yellow_cards_average)\n",
    "\n",
    "team_vip_pro = euro12[euro12['Goals'] > 6]\n",
    "print(team_vip_pro)\n",
    "#7\n",
    "only_G = euro12[euro12['Team'].str.startswith('G')]\n",
    "print(only_G)\n",
    "#8\n",
    "print(euro12.iloc[:, : 7])\n",
    "#9\n",
    "print(euro12.iloc[:, : -3])\n",
    "#10\n",
    "print(euro12[['Goals', 'Team', 'Shooting Accuracy', 'Yellow Cards', 'Red Cards']])\n",
    "#11\n",
    "nature_selective = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])]\n",
    "print(nature_selective['Team', 'Shooting Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai 21\n",
    "#1\n",
    "drink = pd.read_csv('drink.csv', index_col= 0)\n",
    "\n",
    "print(drink.dtypes)\n",
    "print(drink.shape)\n",
    "print(drink.columns)\n",
    "print(drink.head())\n",
    "print(drink.tail())\n",
    "#2\n",
    "average_beer_consumption_in_each_continent = drink.groupby('Continent')['Beer'].mean()\n",
    "#3\n",
    "wine_describe_in_each_continent = drink.groupby('Continent')['Wine'].describe()\n",
    "#4\n",
    "average_beer_and_wine_consumption_in_each_continent = drink.groupby('Continent')[['Beer', 'Wine']].mean()\n",
    "#5\n",
    "median_beer_and_wine_consumption_in_each_continent = drink.groupby('Continent')[['Beer', 'Wine']].median()\n",
    "#6\n",
    "average_spirit_servings = drink.groupby('Continent')['spirit_servings'].mean()\n",
    "highest_spirit_servings = drink.groupby('Continent')['spirit_servings'].max()\n",
    "lowest_spirit_servings = drink.groupby('Continent')['spirit_servings'].min()\n",
    "#7\n",
    "the_big_5 = drink.sort_values(by= 'Beer', ascending= False).head()\n",
    "the_small_5 = drink.sort_values(by= 'Beer', ascending= True).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai22\n",
    "stock1 = {'date', \n",
    "          'symbol', \n",
    "          'open', \n",
    "          'high', \n",
    "          'low', \n",
    "          'close', \n",
    "          'volume'}\n",
    "stock1_df = pd.DataFrame(stock1)\n",
    "stock1_df.to_csv('stock1.csv', \n",
    "                 index= False)\n",
    "\n",
    "stock2 = {'date', \n",
    "          'symbol', \n",
    "          'open', \n",
    "          'high', \n",
    "          'low', \n",
    "          'close', \n",
    "          'volume'}\n",
    "stock2_df = pd.DataFrame(stock2)\n",
    "stock2_df.to_csv('stock2.csv', \n",
    "                 index= False)\n",
    "\n",
    "company = {'name',\n",
    "           'employees',\n",
    "           'headquarters_city',\n",
    "           'headquarters_state'}\n",
    "company_df = pd.DataFrame(company)\n",
    "company_df.to_csv('companies.csv',\n",
    "                  index= False)\n",
    "#1\n",
    "stock1 = pd.read_csv('stock1.csv')\n",
    "print(stock1.head())\n",
    "print(stock1.tail())\n",
    "print(stock1.dtypes)\n",
    "stock1.info()\n",
    "\n",
    "stock2 = pd.read_csv('stock2.csv')\n",
    "print(stock2.head())\n",
    "print(stock2.tail())\n",
    "print(stock2.dtypes)\n",
    "stock2.info()\n",
    "\n",
    "companies = pd.read_csv('companies.csv')\n",
    "print(companies.dtypes)\n",
    "companies.info()\n",
    "#2\n",
    "stock1['high'] = stock1['high'].fillna(stock1.groupby('symbol')['high'].transform('max'))\n",
    "\n",
    "stock1['low'] = stock1['low'].fillna(stock1.groupby('symbol')['low'].transform('min'))\n",
    "\n",
    "print(stock1)\n",
    "#3\n",
    "stocks = pd.concat([stock1, \n",
    "                    stock2], \n",
    "                    axis= 0, \n",
    "                    ignore_index= True)\n",
    "\n",
    "print(stocks.head(15))\n",
    "\n",
    "print(stocks.tail(15))\n",
    "#4\n",
    "stocks_companies = pd.merge(stocks,\n",
    "                            companies,\n",
    "                            left_on= 'symbol',\n",
    "                            right_on = 'name',\n",
    "                            how= 'left')\n",
    "print(stocks_companies.head())\n",
    "#5\n",
    "company_average = stocks_companies.groupby('name')[['open',\n",
    "                                                    'high',\n",
    "                                                    'low',\n",
    "                                                    'close',\n",
    "                                                    'volume']].mean()\n",
    "print(company_average)\n",
    "#6\n",
    "close_status = stocks_companies.groupby('name')['close'].agg(average_close = 'mean',\n",
    "                                                             max_close = 'max',\n",
    "                                                             min_close = 'min')\n",
    "print(close_status)\n",
    "#7\n",
    "stocks_companies[\"parsed_time\"] = pd.to_datetime(stocks_companies[\"date\"])\n",
    "\n",
    "print(stocks_companies[\"parsed_time\"].dtype)\n",
    "print(stocks_companies.head())\n",
    "#8\n",
    "stocks_companies[\"result\"] = np.where(stocks_companies[\"close\"] > stocks_companies[\"open\"],\n",
    "                                      \"up\",\n",
    "                                      \"down\")\n",
    "print(stocks_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79580474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "file_name = \"ml-latest-small.zip\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(file_name, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "movies = pd.read_csv(file_name, compression= 'zip')\n",
    "ratings = pd.read_csv(file_name, compression= 'zip')\n",
    "#1\n",
    "print(movies)\n",
    "print(movies.info())\n",
    "print(ratings)\n",
    "print(ratings.info())\n",
    "#2\n",
    "movies = movies.dropna()\n",
    "print(movies)\n",
    "ratings = ratings.dropna()\n",
    "ratings = ratings[pd.to_numeric(ratings['rating'], \n",
    "                                errors='coerce').notnull()]\n",
    "ratings['rating'] = ratings['rating'].astype(float)\n",
    "print(ratings)\n",
    "#3\n",
    "movie_rating = pd.merge(movies, ratings, on=\"movieId\", how=\"left\")\n",
    "print(movie_rating)\n",
    "#4\n",
    "sorted_movie_rating = movie_rating.sort_values(by=\"rating\", ascending=False)\n",
    "print(sorted_movie_rating)\n",
    "#5\n",
    "print(movie_rating.describe())\n",
    "#6\n",
    "movie_rating[\"parsed_time\"] = pd.to_datetime(movie_rating[\"timestamp\"], unit='s')\n",
    "print(movie_rating)\n",
    "#7\n",
    "plt.figure(figsize=(8,5))\n",
    "movie_rating['rating'].hist(bins= 10, \n",
    "                            edgecolor= 'black')\n",
    "plt.title('Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "top_movies = movie_rating.groupby('title')['rating'].mean().sort_values(ascending=False).head(10)\n",
    "plt.figure(figsize=(10,6))\n",
    "top_movies.plot(kind='bar', \n",
    "                color='skyblue')\n",
    "plt.title('Top 10 Movies by Average Rating')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.xticks(rotation=45, \n",
    "           ha='right')\n",
    "plt.show()\n",
    "\n",
    "ratings_count = movie_rating.groupby('title')['rating'].count().sort_values(ascending=False).head(10)\n",
    "plt.figure(figsize=(10,6))\n",
    "ratings_count.plot(kind= 'bar', \n",
    "                   color= 'orange')\n",
    "plt.title('Top 10 Movies by Number of Ratings')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.xticks(rotation=45, \n",
    "           ha='right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
